import * as faceLandmarksDetection from "@tensorflow-models/face-landmarks-detection";
import "@tensorflow/tfjs-backend-webgl";

const EAR_THRESHOLD = 0.27;
let model;
let event;
let blinkCount = 0;

const loadModel = async () => {
	model = await faceLandmarksDetection.load(
		faceLandmarksDetection.SupportedPackages.mediapipeFacemesh,
		{ maxFaces: 1 }
	);
};

const setUpCamera = async (videoElement) => {
	video = videoElement;
	const mediaDevices = await navigator.mediaDevices.enumerateDevices();

	const defaultWebcam = mediaDevices.find(
		(device) =>
			device.kind === "videoinput" && device.label.includes("Built-in")
	);

	const cameraId = defaultWebcam ? defaultWebcam.deviceId : null;

	const stream = await navigator.mediaDevices.getUserMedia({
		audio: false,
		video: {
			facingMode: "user",
			deviceId: cameraId,
			width: 500,
			height: 500,
		},
	});

	video.srcObject = stream;
	video.play();
	video.width = 500;
	video.height = 500;
};

async function startPrediction(video) {
	// Sending video to model for prediction
	const predictions = await model.estimateFaces({
		input: video,
		returnTensors: false,
		flipHorizontal: false,
		predictIrises: true,
	});

	if (predictions.length > 0) {
		predictions.forEach((prediction) => {
			// Right eye parameters
			const lowerRight = prediction.annotations.rightEyeUpper0;
			const upperRight = prediction.annotations.rightEyeLower0;
			const rightEAR = getEAR(upperRight, lowerRight);
			// Left eye parameters
			const lowerLeft = prediction.annotations.leftEyeUpper0;
			const upperLeft = prediction.annotations.leftEyeLower0;
			const leftEAR = getEAR(upperLeft, lowerLeft);

			// True if the eye is closed
			const blinked = leftEAR <= EAR_THRESHOLD && rightEAR <= EAR_THRESHOLD;

			// Determine how long you blinked
			if (blinked) {
				event = {
					shortBlink: false,
					longBlink: false,
				};
				blinkCount += 1;
			} else {
				event = {
					shortBlink: blinkCount <= 5 && blinkCount !== 0,
					longBlink: blinkCount > 5,
				};
				blinkCount = 0;
			}
		});
	}
	return event;
}

const predict = async () => {
	let result;
	if (videoRef.value.srcObject != null) {
		result = await blinkCapture.startPrediction(videoRef.value);
	}
	if (result) {
		if (result.longBlink) {
			console.log("long blink");
		} else if (result.shortBlink) {
			console.log("short blink");
		}
	}
	requestAnimationFrame(predict);
};

function getEAR(upper, lower) {
	function getEuclideanDistance(x1, y1, x2, y2) {
		return Math.sqrt((x2 - x1) * (x2 - x1) + (y2 - y1) * (y2 - y1));
	}

	return (
		(getEuclideanDistance(upper[5][0], upper[5][1], lower[4][0], lower[4][1]) +
			getEuclideanDistance(
				upper[3][0],
				upper[3][1],
				lower[2][0],
				lower[2][1]
			)) /
		(2 *
			getEuclideanDistance(upper[0][0], upper[0][1], upper[8][0], upper[8][1]))
	);
}

export { loadModel, startPrediction, predict, setUpCamera };
